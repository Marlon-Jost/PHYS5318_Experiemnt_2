{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8a40229-fd6f-4a82-892a-4492e876097a",
   "metadata": {},
   "source": [
    "# NEWER UPDATE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a24e591-7914-4ec1-91a9-6c066ed1fb2f",
   "metadata": {},
   "source": [
    "# Femtosecond laser imaging photobleaching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46679a61-f274-4dfe-84b2-e5429d4c77f6",
   "metadata": {},
   "source": [
    "## 1. Load the data and get to know it\n",
    "\n",
    "When dealing with a new dataset, we need to ask these basic questions about the data:\n",
    "- what is the data trying to describe?\n",
    "- how was the data acquired?\n",
    "- what were the conditions when data was acquired?\n",
    "- what physical/chemical/... phenomena can affect the process of data acquisition?\n",
    "- what types of questions need to be answered using this data?\n",
    "\n",
    "Then after acquiring as much information about the data as possible, it's time to explore it ourselves! As \"Scientists\" we need to think critically about everything, especially the data that we acquire. There are ocassions in which the integrity, validity, interpretation, etc. are faulty and need to be revised.\n",
    "\n",
    "In order to answer these questions it is usually necessary to thoughtfully analyze the data and have contact with the provider of the data along the way. Unfortunately, it is not feasible to contact the data providers for this lab, but it is still good practice to ask yourself (or your TAs) these questions as you continue with this analysis. Additionally, this lab will teach you how to engage with new and unfamiliar datasets; understanding the data that you have been provided, posing new questions, and finding the answers to these questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c1bb13-3e26-4078-a442-b18881c7602f",
   "metadata": {},
   "source": [
    "## Photobleaching\n",
    "> [Photobleaching][1] refers to the photochemical alteration of a dye or a fluorophore molecule such that it is permanently unable to fluoresce.\n",
    "\n",
    "The main aim of this homework is to observe, quantify and analyze an example of fluorophore bleaching. In this dataset, the bleaching is reflected as a decrease in the intensity of the pixels.\n",
    "\n",
    "[1]: https://en.wikipedia.org/wiki/Photobleaching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5226b1b-e8a7-41e2-9991-a294f023acdc",
   "metadata": {},
   "source": [
    "### 1.2 Load the data\n",
    "\n",
    "Load the data and retrieve the `femtosecond laser data` from the data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50e1379-ebc1-4bc6-9eea-8b666bdaf8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from h5py import File as h5File\n",
    "with h5File(\"PHYS5318_Experiment2_datasets/FemtosecondLaser_1.h5\") as file:\n",
    "    img_femtolaser = file['data'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67c5be9-51f6-4cf9-b101-54295bb95ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"type of the `file` object:\", type(file) )\n",
    "print( \"shape/dimensions of the data:\", img_femtolaser.shape )  # shape = ( timestamps, width of the image, height of the image )\n",
    "print( \"pixel value at time index `10`, width index `50` and height index `75`: \", img_femtolaser[10,50,75] )\n",
    "print( \"pixel values at during time index `5` through `10`, width index `50` and `55`, and height index `75` and `80`: \", img_femtolaser[5:10,50:55,75:80] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020fcacf-25fd-47d4-9ed3-508f9194574c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1.2.1: plot first and last frames, e.g. img_femtolaser[0,:,:] is the first frame\n",
    "# Hint1: use the plotting function `matplotlib.pyplot.imshow` from `matplotlib` module (documentation: https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.imshow.html).\n",
    "# Hint2: use the arguments `vmin=0` and `vmax=1` to avoid automatic adjustment of brightness by matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1c7280-a948-449d-9018-e2969fdf55c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1.2.2: plot a few more frames to show photobleaching over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e739bf40-eec4-4a8e-91e4-3ff237539286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1.2.3: can we use a smaller region in each frame/image to extract brightness and observe bleaching?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1132abb-8260-4fe7-8e97-d3fbd4f00595",
   "metadata": {},
   "source": [
    "### 1.3 Noise in the data\n",
    "Arrays of sensors in the cameras can record random noise due to a multitude of sources, [Image Noise - Types][6]. In this dataset the noise is independent and sparse. One method to reduce this type of noise is blurring or spatial-smoothing. Within this category of blurring there are mutliple different approaches: replace every pixel by the average of surrounding pixels (e.g. [8-connectivity][1]), more continuous blurring methods, e.g. [Gaussian Blur][2], more statistically robust blurring methods, e.g. [Median Filtering][3].\n",
    "\n",
    "We will use a less aggressive blurring by applying [Box Averaging][4] of size (3,3) to all the frames.\n",
    "\n",
    "```python\n",
    "import cv2 as cv  # OpenCV Version at 2023/07/06\n",
    "# Do not use `cv.imshow` for this tutorial and in this notebook\n",
    "```\n",
    "\n",
    "[1]: https://en.wikipedia.org/wiki/Pixel_connectivity#8-connected\n",
    "[2]: https://en.wikipedia.org/wiki/Gaussian_blur\n",
    "[3]: https://docs.opencv.org/3.4/d4/d86/group__imgproc__filter.html#ga564869aa33e58769b4469101aac458f9\n",
    "[4]: https://docs.opencv.org/3.4/d4/d86/group__imgproc__filter.html#ga8c45db9afe636703801b0b2e440fce37\n",
    "[5]: https://pypi.org/project/opencv-python/\n",
    "[6]: https://en.wikipedia.org/wiki/Image_noise#Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8e9464-985e-47ee-b381-755ed37c976a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1.3.1: plot the first frame to have it here as a reference for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c987966-12fa-4bc5-84ab-72004d3eee09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1.3.2: apply a box blur of size (3,3) on the first frame and plot it\n",
    "# hint: box blur is available as a function in the `cv` module -> `cv.blur` (documentation: Image Blurring section at https://docs.opencv.org/4.x/d4/d13/tutorial_py_filtering.html)\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce54d6d8-d6b9-4460-9dae-52ce348ad5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1.3.3: compare the blurred with the original first frame qualitatively\n",
    "# Although the pictures/plots look similar, it is important to use the blurred version. Explain why this is so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf20d441-44f0-4908-a515-346b081847ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1.3.4: apply the blurring in a for loop and store the blurred frames in a new array of the same shape of `img_femtolaser`\n",
    "# name the blurred array `img_femtolaser_blurred`\n",
    "# Hint1: if you use a list to store frames, don't forget to convert to numpy arrays again, e.g. np.array(LIST_VARIABLE)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5212b65d-f1a3-4b65-93c7-bc13b2f3f8ce",
   "metadata": {},
   "source": [
    "> We will cary out the rest of the analysis only using the `img_femtolaser_blurred` image frames."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4cdd66-aca8-4c01-bc2b-495d41acb6d2",
   "metadata": {},
   "source": [
    "## 2. Localize the cell\n",
    "Now that we've taken a look at the original and done some blurring (e.g. spatial smoothing) to the images, it's time to localize the cell's bright spot. For the sake of analyzing the bleaching effect, we need to identify some region inside the cell and track it's brightness properties throughout the imaging session.\n",
    "\n",
    "We will use a fixed mask over multiple time frames to extract both spatial and temporal variations in pixel intensities within the region of interest inside the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f4d4d0-e093-4329-8ea4-b86aaa128919",
   "metadata": {},
   "source": [
    "### 2.1 Mask a specific region in all frames\n",
    "By looking at frames at multiple times, we will define a mask that corresponds to bright regions inside the cell. This region should be small enough to ignore dark regions outside or on the boundary of the cell, while still large enough to capture some spatial variations inside the cell (possibly due to inevitable imaging noises).\n",
    "\n",
    "After that, we will define and quantify statistics which capture the behavior of bleaching over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f26ed26-98ba-41c9-9223-767c091729ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2.1.1 find a fixed point that is within a bright region inside the cell. As the cell shifts slightly through time, check that the point you picked never contains background values. Do this qualitatively by looking at multiple frames.\n",
    "# Plot multiple frames with some annotation around your fixed point, e.g. add a red dot on multiple frames\n",
    "# Store the coordinates of the point in two variables `idx_i` and `idx_j`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88915fac-ea9c-478a-a161-de53a78d7c0a",
   "metadata": {},
   "source": [
    "[Image Masking][1] refers to the process of selectively setting some pixel values in an image to zero, and keeping other pixels unchanges. Based on the visual of different frames, we can determine a True/False mask (2-dimensional array) that corresponds to a region inside the cell across all the frames.\n",
    "\n",
    "[1]: https://homepages.inf.ed.ac.uk/rbf/HIPR2/mask.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aba5f6-0568-49cd-8ef7-9192a2e292a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2.1.2 Now define a 2d-array which corresponds to a region around the point you found before\n",
    "# e.g. this array should have `False` value outside the desired region and `True` inside\n",
    "# You can visualize this mask using the hints in the next cell.\n",
    "# Hint1: The size of the circle will determine the reliability of your final conclusions. Be intentional when choosing the size of your region\n",
    "\n",
    "ni, nj = img_femtolaser_blurred[0].shape\n",
    "radius = # Students will be changing this parameter\n",
    "mask_cell = np.zeros((ni, nj), dtype=np.bool_)\n",
    "for i in range(ni):\n",
    "    for j in range(nj):\n",
    "        # Define a ciruclar region\n",
    "        r = np.sqrt( (i-idx_i)**2 + (j - idx_j)**2 )\n",
    "        if r <= radius:\n",
    "            mask_cell[i,j] = True\n",
    "n_pixels_mask = mask_cell.sum()   # Number of pixels inside the selected region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f6867b-5a14-4081-a573-9da76f34979d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2.1.3: plot the mask on top of each image for both first and last frame in a joint plot, e.g top image corresponds to first frame with mask annotated, and bottom image corresponds to the last frame with mask annotated\n",
    "# you can use `matplotlib.pyplot.subplots` to create a joint/subplots.  (documentation: https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.subplots.html)\n",
    "# Hint1: you can easily make the masked region visible by adding it to an image before plotting, e.g. plt.imshow(img+mask_cell, vmin=0, vmax=1)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(2, 1, figsize=(24,12), sharex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62018ab5-7e6d-4487-aeee-829e9e0d8281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2.1.4: extract all pixel intensities inside the cell mask you have defined, e.g. for an image frame img[mask_cell]\n",
    "# Create an array named 'intensities' of the shape (NUMBER_OF_FRAMES, n_pixels_mask) and populate it with pixel intensities for each frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159b2080-88e9-46ac-bca7-b076c7e75429",
   "metadata": {},
   "source": [
    "### 2.2 Find the bleaching start time\n",
    "In this dataset, the bleaching does not start from the initial frame. To focus on the analysis of bleaching dynamics, we first limit intensities to frame indices after the bleaching has started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5031ce88-c771-4460-90ec-0f25b2a72f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2.2.1 Plot the average intesity at each time/frame index, and, using the plot, find the time index at which the bleaching has started\n",
    "# Call this index `idx_bleaching_begin` and annotate it on the plot with a red vertical line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde735a6-9cf7-4437-8561-30f3a5b45706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-define the variable `intensities` as follows `intensities = intensities[idx_bleaching_begin:]`\n",
    "# Run this only after you have finalized the value of `idx_bleaching_begin`\n",
    "intensities = intensities[idx_bleaching_begin:]\n",
    "temp_list = temp_list[idx_bleaching_begin:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bddef28-f0c7-4488-bfe3-2e06869451db",
   "metadata": {},
   "source": [
    "# 3. Fit exponential funcion\n",
    "\n",
    "We want to analyze the dependence of intensities vs. time. Our guess is that the dependence should be `exponentially decaying`. To estimate the exponential dependence we will use the Ordinary Least Squares method. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62faf16e-681a-45c4-b2f6-a317285f6e39",
   "metadata": {},
   "source": [
    "### 3.1 Aggregate intensities\n",
    "\n",
    "First we will define a time index array to represent the time at each frame. Then for each frame, we will aggregate the pixel intensities into two statistical groups which represent average behavior and it's uncertainty respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de485aa9-b97a-42bd-873a-c9f433bffc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3.1.1: Calculate average and standard error of the masked pixel intensities (`intensities`). \n",
    "# At each frame store your final results as `intensities_mu` and `intensities_ste` as averages and standard errors respectively\n",
    "n_times, n_pixels_mask = intensities.shape\n",
    "ts = np.arange(n_times)\n",
    "intensities_mu, intensities_ste = np.zeros(n_times), np.zeros(n_times)\n",
    "for idx in range(n_times):\n",
    "    pixel_values = intensities[idx]\n",
    "    # Calculate mean and ste of the pixel values and store them\n",
    "    # in `intensities_mu` and `intensities_ste` arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b828cc-10cd-4bfc-b5a0-6988cdf01181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3.1.2: create an error bar plot of `intensities_mu` and errors `intensities_ste` vs `ts` (documentation: https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.errorbar.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acb3348-26f1-4638-965f-5ddfcb66f71a",
   "metadata": {},
   "source": [
    "### 3.2 Best exponential fit using Ordinary Least Squares method\n",
    "\n",
    "Let's find the best exponential fit parameters using the [Ordinary Least Squares method][1]. The function [scipy.optimize.curve_fit][2] is already written to perform this for us. \n",
    "\n",
    "[1]: https://byjus.com/maths/least-square-method/#:~:text=The%20least%20square%20method%20is,the%20points%20from%20the%20curve.\n",
    "[2]: https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d3e86a-3e62-4b52-b814-55a75f097bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3.2.1: define a function in python that given `t`, `A` and `beta`, returns `A*exp(-beta*t)`.\n",
    "# Name this function `func_exp`.\n",
    "# For example this is how to use the function to calculate `1.2 * exp(-2.0*0.1)` (A = 1.2, beta = 2.0, t = 0.1): `func_exp(0.1, 1.2, 2.0)` this should return the value of `1.2 * exp(-2.0*0.1)`.\n",
    "def func_exp(t, A, beta):\n",
    "    # Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf32492a-4211-4682-a805-509e96c2843e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3.2.2: following the documentation of `scipy.optimize.curve_fit`, and using `func_exp` and `intensities_mu`,\n",
    "# find best exponential fit parameters using Ordinary Least Squares.\n",
    "# Name these parameters `A_ols` and `beta_ols` and print them.\n",
    "# Hint: you might need to use the argument `p0` explicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadac456-526a-4b2a-b4cb-e38ae4dc55a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3.2.4: plot the error bar for `intensities_mu` vs `ts` (errors equal to `intensities_ste`), and\n",
    "# add best fit exponentials using parameters from OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f2de00-e682-42a8-9f83-134fbc996614",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebc7c64-ad04-486f-8001-a23de335f576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89434862-bc5c-4668-9493-7b91aeddfeeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16809e51-aa3b-49ac-9e54-8f184c3a27f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1a6141-2ca1-4c99-b95b-c68da2c2655b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281ba069-e03b-43b7-a8b2-1f34b8a50049",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4965a49e-fffc-4610-b040-25d81e12afa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d38ee31-5535-4a58-97ff-7786cb245b2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5921d2ad-26d9-4d5a-a699-a84b91f32f87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4a5feb-11fc-42ca-bb51-5637454a2837",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PHYS5318",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
